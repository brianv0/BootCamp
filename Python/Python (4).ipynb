{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Python Advanced Topics\n",
    "\n",
    "Author: Joe DeRose\n",
    "\n",
    "Instead of diving deeply into any one particular package, the goal of this session will be to guide you through a few exercises that use packages that you may find useful in your research. \n",
    "\n",
    "To start, make sure you have the following packages installed:\n",
    "- scikit-learn\n",
    "- astropy\n",
    "- healpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from sklearn import datasets, cross_validation, preprocessing, neighbors, metrics, grid_search\n",
    "from matplotlib.colors import ListedColormap\n",
    "import healpy as hp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading, writing and manipulating data using astropy\n",
    "Astropy is a [well documented](http://astropy.readthedocs.org/en/latest/index.html) library containing functionality useful for many every day astrophysical applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll go over how to load and manipulate Flexible Image Transport System (FITS) files, a common binary data format for astrophysical data.\n",
    "There are a number of python packages with FITS reading functionality, but today we will focus on astropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdulist = fits.open('COM_CompMap_CMB-commrul_0256_R1.00.fits')\n",
    "hdulist.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening a fits file gives us a list of the 'Header Data Units' or HDUs which contain the data that is stored in the file. The info method lists the properties of each of the HDUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdulist[1].header #We can take a look at the header of each of the HDUs to see what data it contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write data in FITS format using astropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's select the data we care about to write to disk\n",
    "whdu = hdulist[1]\n",
    "col1 = whdu.columns['I']\n",
    "col2 = whdu.columns['VALMASK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = fits.ColDefs([col1, col2]) #Combine the columns together\n",
    "tbhdu = fits.BinTableHDU.from_columns(cols) #and turn them into a table\n",
    "tbhdu.writeto('intensity.fits') #write the table to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Read in the file that we just wrote and select the intensity map column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Healpy\n",
    "Now that we've learned how to read and write FITS data using astropy, let's play around with the data we loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Healpy](https://healpy.readthedocs.org/en/latest/) is a very useful [HEALPix](http://healpix.jpl.nasa.gov/) manipulation package, among other things.  \n",
    "\n",
    "Briefly, HEALPix is a commonly used decomposition of the sphere. It has useful properties such as:\n",
    "- All pixels are equal in area\n",
    "- Pixel centers lie on lines of constant latitude\n",
    "- [many more](http://healpix.jpl.nasa.gov/pdf/intro.pdf)\n",
    "\n",
    "A HEALPix map is characterized by its N<sub>side</sub> parameter, describing the number of divisions along the side of a base resolution pixel needed to obtain the desired decomposition. The number of pixels is then N<sub>pix</sub>=12N<sub>side</sub><sup>2</sup>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nside = hdulist[1].header['NSIDE']\n",
    "print(hp.nside2npix(nside))\n",
    "print(len(hdulist[1].data)) #healpix map is just array w/ N_pix elements (N_side = 256 here)\n",
    "print(hp.nside2pixarea(nside, degrees=True)) #area of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lots of nice coordinate conversion functionality\n",
    "theta, phi = hp.pix2ang(nside, np.arange(12*nside**2), nest=True) #get angular locations of pixel centers\n",
    "                                                                  #but be careful, depending on the coordinate system\n",
    "                                                                  #used, they may not comply with typical conventions\n",
    "vec = hp.ang2vec(theta, phi) #get unit vectors corresponding to those coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colormap = ListedColormap(np.loadtxt(\"Planck_Parchment_RGB.txt\")/255.) #to make it pretty\n",
    "hp.mollview(hdulist[1].data['I'], nest=True, cmap=colormap) #nested numbering scheme "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Healpix has some convinient coordinate transformation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "euler_angs = [45, 45, 0] #we can define an arbitraty rotation using Euler angles\n",
    "rot = hp.Rotator(euler_angs, eulertype='XYZ')\n",
    "print(rot.mat) #the rotation matrix in cartesian basis defined by euler_angs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp.mollview(hdulist[1].data['I'], nest=True, cmap=colormap, rot=euler_angs)\n",
    "hp.graticule() #plot the graticule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp.mollview(hdulist[1].data['I'], nest=True, cmap=colormap, coord=['G', 'E'])\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mmap = hp.ma(hdulist[1].data['I']) \n",
    "mmap.mask = np.logical_not(hdulist[1].data['VALMASK']) #we can mask out the galactic plane\n",
    "hp.mollview(mmap, nest=True, cmap=colormap, coord=['G', 'E'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astropy has some very convenient coordinate transformation functionality as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "ra = np.arange(10)\n",
    "dec = np.arange(10)\n",
    "c = SkyCoord(ra=ra*u.degree, dec=dec*u.degree, frame='icrs')\n",
    "c = SkyCoord(ra, dec, frame='icrs', unit='deg') #alternatively\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.galactic #to convert between different coordinate systems, just get the relevant attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Mask out all pixels with RA>90 in the CMB map and plot them using the Mollweide projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Scikit-learn\n",
    "There is [a lot](http://scikit-learn.org/stable/) here, so we'll only just scratch the surface. There are a very large number of machine learning algorithms implemented in this package. I'll use just one for the purposes of this tutorial, focusing on a typical model building workflow.\n",
    "\n",
    "We'll cover:\n",
    "- Data pre-processing and feature selection\n",
    "- Model selection/validation\n",
    "- Model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston() #load in a canned data set\n",
    "X = boston.data\n",
    "Y = boston.target\n",
    "fields = boston.feature_names\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subplot(131)\n",
    "scatter(X[:,11],Y)\n",
    "subplot(132)\n",
    "scatter(X[:,10],Y)\n",
    "subplot(133)\n",
    "scatter(X[:,9],Y)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the dynamical range of some of the features is much larger than that of others. Depending on the learning algorithm, this can lead to non-optimal performance, so it is always good practice to rescale your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_scaled = preprocessing.scale(X)\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X_scaled, Y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try to predict the price of the homes based on the other features based on a k-nearest neighbors algorithm. The most basic version of this algorithm predicts the label for the query point as the mean of the labels of the k nearest neighbors to the query point in feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_neighbors = 5\n",
    "weights = 'uniform'\n",
    "reg = neighbors.KNeighborsRegressor(n_neighbors, weights=weights)\n",
    "reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = reg.predict(X_test)\n",
    "\n",
    "# how well did we do?\n",
    "mse = metrics.mean_squared_error(Y_test,Y_pred)\n",
    "print(mse)\n",
    "plot(Y_test,Y_pred - Y_test,'o')\n",
    "xlabel(\"True Median House Price ($1,000)\")\n",
    "ylabel(\"Residual\")\n",
    "hlines(0,min(Y_test),max(Y_test),color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Explore the KNN model parameters. See if you can find a combination that minimzes the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can do this more systematically using the GridSearchCV sklearn function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'n_neighbors':range(1,5), 'weights':['uniform', 'distance']}\n",
    "cvreg = grid_search.GridSearchCV(neighbors.KNeighborsRegressor(), params, n_jobs=-1)#n_jobs parameter sets the number of processors\n",
    "cvreg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvreg.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = cvreg.predict(X_test)\n",
    "\n",
    "# how well did we do?\n",
    "mse = metrics.mean_squared_error(Y_test,Y_pred)\n",
    "print(mse)\n",
    "plot(Y_test,Y_pred - Y_test,'o')\n",
    "xlabel(\"True Median House Price ($1,000)\")\n",
    "ylabel(\"Residual\")\n",
    "hlines(0,min(Y_test),max(Y_test),color=\"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
